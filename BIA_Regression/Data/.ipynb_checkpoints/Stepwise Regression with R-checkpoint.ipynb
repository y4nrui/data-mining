{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: http://www.sthda.com/english/articles/37-model-selection-essentials-in-r/154-stepwise-regression-essentials-in-r/\n",
    "\n",
    "**To run the R codes on Jupyter notebook, type “conda install -c r r-essentials” on your terminal – it will install the R kernel and some important R packages (e.g. dplyr, ggplot2, etc.)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the required packages \n",
    "library(tidyverse)\n",
    "library(caret) \n",
    "library(leaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "\n",
    "df_housing <- read.csv(\"train.csv\", stringsAsFactors = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get an overview of the train data set\n",
    "#Click on white space below to expand out the code output\n",
    "\n",
    "glimpse(df_housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1: Using stepAIC()\n",
    "Selects the best model by AIC (Akaike Information Criterion). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(MASS)\n",
    "\n",
    "#Fit your initial model to begin the regression \n",
    "\n",
    "full_model <- lm(SalePrice ~ ., data = df_housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three ways to do stepwise regression: (1) Backward, (2) Forward, (3) Stepwise. To select a particular model, you have to change the value in **direction**: (i) \"both\" (stepwise regression), (ii) \"backward\" (for backward regression) and \"forward\" (for forward selection). \n",
    "\n",
    "**trace** can be either TRUE or FALSE. TRUE means you want to see the results at each iteration, while FALSE does not show you each step, you just get the best final model at the end. If you have more variables then TRUE will give you a pretty long list of steps taken. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stepwise_model <- stepAIC(SalePrice ~ ., direction = \"both\", trace = FALSE)\n",
    "\n",
    "# backwards_model <- stepAIC(SalePrice ~ ., direction = \"backward\", trace = FALSE)\n",
    "\n",
    "# forwards_model <- stepAIC(SalePrice ~ 1, direction = \"forward\", scope=formula(full_model), trace = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results of the final model \n",
    "\n",
    "summary(stepwise_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2: Using regsubsets()\n",
    "Has tuning parameter **nvmax** specifying the maximal number of predictors to incorporate in the model. It returns multiple models with different size up to nvmax. You need to compare the performance of the different models for choosing the best one. \n",
    "\n",
    "regsubsets() has the option method, which can take the values “backward”, “forward” and “seqrep” (seqrep = sequential replacement, combination of forward and backward selections)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models <- regsubsets(SalePrice ~ ., data = df_housing, nvmax = ?, method = 'seqrep')\n",
    "\n",
    "summary(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 3: CV and GridSearch\n",
    "\n",
    "The train() function [caret package] provides an easy workflow to perform stepwise selections using the leaps and the MASS packages. It has an option named method, which can take the following values:\n",
    "\n",
    " - \"leapBackward\", to fit linear regression with backward selection\n",
    " - \"leapForward\", to fit linear regression with forward selection\n",
    " - \"leapSeq\", to fit linear regression with stepwise selection\n",
    " \n",
    "You also need to specify the tuning parameter nvmax, which corresponds to the maximum number of predictors to be incorporated in the model.\n",
    "\n",
    "For example, you can vary nvmax from 1 to 5. In this case, the function starts by searching different best models of different size, up to the best 5-variables model. That is, it searches the best 1-variable model, the best 2-variables model, …, the best 5-variables models.\n",
    "\n",
    "\n",
    "We can use 5/10-fold cross-validation to estimate the average prediction error (RMSE) of each of the models. The RMSE statistical metric is used to compare the models and to automatically choose the best one, where best is defined as the model that minimize the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set seed for reproducibility\n",
    "set.seed(42)\n",
    "\n",
    "#Set up repeated k-fold cross-validation, indicate the number of folds you want\n",
    "train_control <- train_control(method = \"cv\", number = 10)\n",
    "\n",
    "#Train the model, indicate the method of regression and range of nvmax numbers to try\n",
    "step_model <- train(SalePrice ~ ., data = df_housing, \n",
    "                   method = \"leapSeq\",\n",
    "                   tuneGrid = data.frame(nvmax = 5:50),\n",
    "                   trControl = train_control)\n",
    "step_model$results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**nvmax**: the number of variable in the model. For example nvmax = 2, specify the best 2-variables model\n",
    "\n",
    "**RMSE** and **MAE** are two different metrics measuring the prediction error of each model. The lower the RMSE and MAE, the better the model.\n",
    "\n",
    "**Rsquared** indicates the correlation between the observed outcome values and the values predicted by the model. The higher the R squared, the better the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the best tuning values (nvmax) selected by the train() function\n",
    "\n",
    "step_model$bestTune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function summary() reports the best set of variables for each model size \n",
    "summary(step_model$finalModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
